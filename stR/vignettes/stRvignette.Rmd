---
title: "Package stR"
author: "Alex Dokumentov"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Package stR}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

This vignette describes some functionality and provides a few examples of how to use package stR.
stR implements method STR, and STR comes as an abbreviation for Seasonal-Trend decomposition by Regression and capital R comes from from R, the name for a popular statistical software. The name is also reminiscent of STL, the method which inspired me to create STR.


## Introducation

There are many packages and methods which work with seasonal data. For example the oldest method for decomposition -- classical additive decomposition -- is implemented in package <code>stats</code>. Here is an example:
```{r, fig.show='hold', fig.width = 7, fig.height = 4.5, cache=TRUE}
m <- decompose(co2)
plot(m)
```
The method attempts to split the data into trend, seasonal and random components.

Another method is STL. It is implemented in packages <code>stats</code> and <code>stlplus</code>. Here is an example:
```{r, fig.show='hold', fig.width = 7, fig.height = 4.5}
plot(stl(log(co2), s.window = "per", t.window = 30))
```

Other packages which implement various versions of seasonal decomposition and seasonal adjustment include: <code>forecast</code>, <code>x12</code>, <code>seasonal</code>, <code>season</code>, <code>seas</code>, <code>deseasonalize</code>.

A few more examples are below:
```{r, results='hide', message=FALSE, echo=FALSE, warning=FALSE, cache=TRUE, autodep=FALSE}
require(forecast)
require(seasonal)
```
```{r, fig.show='hold', fig.width = 7, fig.height = 4.5, cache=TRUE, autodep=FALSE}
require(forecast)
plot(tbats(co2))
```

```{r, fig.show='hold', fig.width = 7, fig.height = 3, cache=TRUE, autodep=FALSE}
require(seasonal)
co2.fit <- seas(co2)
plot(co2.fit, trend = T)
```


After looking at the above examples the reader might have a very legitimate question: Why do we need another method for seasonal decomposition?

A simple answer is that

  1. the new methid has a reach set of features (and allows to implement more features) and
  2. the method also has theoretical background, which satisfies me more than other methods.

This vignette provides more details on the first claim.


## Getting started

In this section we will continue working with <code>co2</code> dataset.
Since <code>co2</code> is of class <code>ts</code>

```{r, fig.show='hold', fig.width = 7, fig.height = 3, cache=TRUE, autodep=FALSE}
class(co2)
```

we can use <code>AutoSTR</code> functon (<code>AutoSTR.ts</code>):

```{r, fig.show='hold', fig.width = 7, fig.height = 3, cache=TRUE, autodep=FALSE, echo=TRUE, warning=FALSE, results='hide'}
co2.fit = AutoSTR(co2)
```
```{r, fig.show='hold', fig.width = 7, fig.height = 3, cache=TRUE, autodep=FALSE}
plot(co2.fit)
```

The execution takes longer than for any of the above mentioned methods. It happens because the <code>AutoSTR</code> function tries to estimate parameters of the corresponding STR model.


## Example with multiple seasonality

Dataset <code>taylor</code> from package <code>forecast</code> provides us with half-hourly electricity demand in England and Wales. It exhibits (at least) two seasonalities -- dayly and weekly. They can bee observed in the subset (4 weeks) of the data below:
```{r, fig.show='hold', fig.width = 7, fig.height = 3, cache=TRUE, autodep=FALSE}
taylor.msts <- msts(log(head(as.vector(taylor), 336*4)), seasonal.periods=c(48,336), ts.frequency=48*7*52.25, start=2000+22/52)
plot(taylor.msts, ylab = "Electricity demand")
```
Since the data in half hour granularity, the daily seasonality is 48 observations and weekly is 336.

The data is <code>msts</code> class time series, and <code>AutoSTR</code> functon (<code>AutoSTR.msts</code>) can be used to decompose the data:
```{r, fig.show='hold', fig.width = 7, fig.height = 3, cache=TRUE, autodep=FALSE, echo=TRUE, warning=FALSE, results='hide'}
taylor.fit = AutoSTR(taylor.msts, gapCV = 48, reltol = 0.001, confidence = 0.95)
```
```{r, fig.show='hold', fig.width = 7, fig.height = 4.5, cache=TRUE, autodep=FALSE}
plot(taylor.fit)
```
The supplied parameters are:

* <code>gapCV = 48</code> -- gaps of 48 observations are used for corss validation
* <code>reltol = 0.001</code> -- this parameter is passed directly to <code>optim</code> function, it controls how well (and for how long) the model parameters are optimized
* <code>confidence = 0.95</code> -- 95% confidence intervals are calculated (used assumptions, which are not always true, are: errors are uncorreleated, model parameters are estimated exactly)


## More internals

Dataset <code>grocery</code> provides us with monthly data of supermarkets and grocery stores turnover in New South Wales:
```{r, fig.show='hold', fig.width = 7, fig.height = 3, cache=TRUE, autodep=FALSE}
plot(grocery, ylab = "NSW Grocery Turnover, $ 10^6")
```


## Even more examples

Even more bla-bla-bla...
